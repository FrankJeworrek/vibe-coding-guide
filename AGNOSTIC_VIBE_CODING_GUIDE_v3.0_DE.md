# Das Universelle Vibe Coding Handbuch v3.0

**Version:** 3.0.0
**Letzte Aktualisierung:** 2026-01-31
**Sprache:** Deutsch
**Status:** Stable Release

**AI-Agnostisch:** Funktioniert mit beliebigen AI-Assistenten (Claude, GPT, Gemini, lokale LLMs) oder menschlichen Teams
**Sprach-Agnostisch:** Funktioniert mit Python, JavaScript, Go, Rust, Java, C#, PHP, Ruby und mehr
**Framework-Agnostisch:** Funktioniert fÃ¼r Web, Mobile, CLI, Desktop, Microservices, Embedded Systems
**Team-Skalierbar:** Funktioniert fÃ¼r Solo-Entwickler bis 20+ Personen Enterprise-Teams

---

## ğŸ“– Inhaltsverzeichnis

**[Teil I: Grundlagen](#teil-i-grundlagen)**
1. [EinfÃ¼hrung: Warum Vibe Coding oft scheitert](#1-einfÃ¼hrung-warum-vibe-coding-oft-scheitert)
2. [Die Vibe Coding Methodik: Ãœberblick](#2-die-vibe-coding-methodik-Ã¼berblick)
3. [Skalierungs-Leitfaden](#3-skalierungs-leitfaden)

**[Teil II: Die 6-Phasen-Architektur](#teil-ii-die-6-phasen-architektur)**
- [Phase 0: Pre-Project Foundation](#phase-0-pre-project-foundation)
- [Phase 1: Implementierungsplan-Exzellenz](#phase-1-implementierungsplan-exzellenz)
- [Phase 2: Session-KontinuitÃ¤t & State-Management](#phase-2-session-kontinuitÃ¤t--state-management)
- [Phase 3: Backup & Recovery](#phase-3-backup--recovery)
- [Phase 4: Decision Logging (ADR-System)](#phase-4-decision-logging-adr-system)
- [Phase 5: Quality Gates & Verification](#phase-5-quality-gates--verification)
- [Phase 6: Kontinuierliches Lernen](#phase-6-kontinuierliches-lernen)

**[Teil III: Praktische Anwendung](#teil-iii-praktische-anwendung)**
7. [VollstÃ¤ndige Workflow-Beispiele](#7-vollstÃ¤ndige-workflow-beispiele)
8. [Kritische Erfolgsfaktoren](#8-kritische-erfolgsfaktoren)
9. [Checklisten](#9-checklisten)
10. [Tool-Auswahl-LeitfÃ¤den](#10-tool-auswahl-leitfÃ¤den)

**[Teil IV: Erweiterte Themen](#teil-iv-erweiterte-themen)**
11. [Team-Skalierungs-Patterns](#11-team-skalierungs-patterns)
12. [AI-Assistenten Strategien](#12-ai-assistenten-strategien)
13. [Security & Compliance](#13-security--compliance)
14. [Performance Optimization](#14-performance-optimization)
15. [Deployment & Operations](#15-deployment--operations)

**[Teil V: Anhang](#teil-v-anhang)**
- [Appendix A: Komplette Script-Bibliothek](#appendix-a-komplette-script-bibliothek)
- [Appendix B: Template-Bibliothek](#appendix-b-template-bibliothek)
- [Appendix C: Fallstudien](#appendix-c-fallstudien)
- [Appendix D: Quick Reference](#appendix-d-quick-reference)
- [Appendix E: Weitere Ressourcen](#appendix-e-weitere-ressourcen)

---

# Teil I: Grundlagen

## 1. EinfÃ¼hrung: Warum Vibe Coding oft scheitert

### 1.1 Das Problem mit Ad-hoc AI-Coding

**Vibe Coding** â€“ das intuitive, flow-basierte Programmieren mit AI-Assistenten â€“ hat die Software-Entwicklung revolutioniert. Mit Tools wie Claude, GPT-4, und Gemini kÃ¶nnen Entwickler in Minuten Code generieren, der frÃ¼her Stunden oder Tage brauchte.

**Aber die RealitÃ¤t ist ernÃ¼chternd:**

âŒ **80% der Vibe Coding Projekte scheitern** vor dem ersten Release
âŒ **Mid-Course Chaos** tritt nach 2-4 Wochen ein, wenn die initiale Begeisterung verfliegt
âŒ **Context-Loss** bei Unterbrechungen fÃ¼hrt zu doppelter Arbeit und Inkonsistenzen
âŒ **Technical Debt** akkumuliert schneller als bei traditioneller Entwicklung
âŒ **Team-Koordination** scheitert, weil jeder Entwickler seinen eigenen "Vibe" hat

**Warum scheitern so viele Projekte?**

Das Problem ist NICHT die AI. Das Problem ist das **Fehlen professioneller Software-Engineering-Praktiken**:

1. **Keine klare Spezifikation** â†’ Mid-Course-Chaos
   - Entwicklung beginnt mit "Lass uns einfach anfangen"
   - Features werden zufÃ¤llig implementiert, keine Priorisierung
   - Nach 3 Wochen: "Warten, was bauen wir eigentlich?"

2. **Fehlender KontinuitÃ¤tsmechanismus** â†’ Context-Loss bei Unterbrechungen
   - Nach Pause: "Was habe ich zuletzt gemacht?"
   - AI-Assistent hat keinen persistenten State
   - Keine Handoff-Informationen zwischen Sessions
   - Ergebnis: Doppelte Arbeit, widersprÃ¼chliche Implementierungen

3. **Keine Backup-Strategie** â†’ Datenverlust bei Crashes
   - "Git reicht ja" â€“ bis Festplatte crasht
   - Keine lokalen Backups, keine Cloud-Redundanz
   - Session-State nicht gesichert
   - Ergebnis: Projekt-Verlust, Wochen verschwendet

4. **UnvollstÃ¤ndige Dokumentation** â†’ Onboarding unmÃ¶glich
   - Code ohne Kontext: "Warum wurde das so implementiert?"
   - Kein README, keine Architektur-Dokumentation
   - Teammitglied kommt dazu: "Wo fange ich an?"
   - Ergebnis: Nur Original-Entwickler kann Code verstehen

5. **Fehlende Entscheidungsdokumentation** â†’ Wiederholte Diskussionen
   - Nach 3 Monaten: "Warum haben wir X statt Y gewÃ¤hlt?"
   - Keine dokumentierten Alternativen und Trade-offs
   - Ergebnis: Dieselben Diskussionen werden immer wieder gefÃ¼hrt

**Die traditionellen Antworten sind FALSCH:**

ğŸš« **"Vibe Coding ist nur fÃ¼r Prototypen"** â†’ Falsch. Mit den richtigen Praktiken funktioniert es fÃ¼r Produktions-Software.
ğŸš« **"Man braucht klassisches Project Management"** â†’ Falsch. ÃœbermÃ¤ÃŸiger Prozess tÃ¶tet den Flow, den Vibe Coding so wertvoll macht.
ğŸš« **"AI-Assistenten sind nicht reif"** â†’ Falsch. Die AI ist fantastisch. Das Problem ist der fehlende professionelle Rahmen.

### 1.2 Die Vibe Coding Philosophie: Das Beste aus beiden Welten

**Dieses Handbuch lÃ¶st das Problem durch einen pragmatischen Mittelweg:**

> **Vibe Coding + professionelle Praktiken = Erfolgreiche Projekte**

**Kernprinzip:**
> **Vorbereitung bestimmt Erfolg oder Scheitern.**
> Phase 0 (1 Woche fÃ¼r mittlere Projekte) schlieÃŸt alle bekannten LÃ¼cken, BEVOR Phase 1 (Implementation) beginnt.

**Die 6-Phasen-Methodik:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 0: Pre-Project Foundation (1 Woche)                â”‚
â”‚  â†’ LÃ¼cken schlieÃŸen BEVOR Implementation beginnt           â”‚
â”‚  â†’ project-charter.md, tech-stack.md, Test-Daten, ADR-001 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: Implementierungsplan-Exzellenz (2-5 Tage)       â”‚
â”‚  â†’ Spezifikation VOR Implementation                        â”‚
â”‚  â†’ Konkrete Deliverables (nicht vage Tasks)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2: Session-KontinuitÃ¤t & State-Management (Setup)  â”‚
â”‚  â†’ YAML-Sessions mit Handoff-Protokoll                     â”‚
â”‚  â†’ Drei-Schichten-Architektur (WHY/WHAT/EXISTS)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 3: Backup & Recovery (Setup)                       â”‚
â”‚  â†’ 5-Layer Backup-Modell (Defense in Depth)               â”‚
â”‚  â†’ Git + Lokal + Cloud + Tracking + Portable              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 4: Decision Logging (ADR-System)                   â”‚
â”‚  â†’ Architecture Decision Records fÃ¼r jede wichtige Wahl    â”‚
â”‚  â†’ Alternatives Considered dokumentiert                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 5: Quality Gates & Verification (pro Phase)        â”‚
â”‚  â†’ QualitÃ¤t eingebaut, nicht nachtrÃ¤glich geprÃ¼ft         â”‚
â”‚  â†’ Automated + Manual + Documentation + CI/CD              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 6: Kontinuierliches Lernen (pro Session)           â”‚
â”‚  â†’ Post-Session Retrospektiven                             â”‚
â”‚  â†’ Prozess-Verbesserungs-Loops                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Was macht diesen Ansatz anders?**

âœ… **Pragmatisch Ã¼ber Perfekt**: Keine akademischen Konzepte, nur was in echten Projekten funktioniert
âœ… **Flow-erhaltend**: Minimaler Overhead wÃ¤hrend der Entwicklung, maximale Struktur in Vorbereitung
âœ… **Sprach-agnostisch**: Funktioniert mit Python, JavaScript, Go, Rust, Java â€“ jeder Technologie
âœ… **Team-skalierbar**: Von Solo-Entwickler bis 20+ Personen Enterprise-Teams
âœ… **AI-agnostisch**: Funktioniert mit Claude, GPT, Gemini, oder lokalen LLMs
âœ… **Erprobt**: Basierend auf 28-Wochen Real-Project (THE_SONG_APP, 15.000+ LOC)

**Was dieses Handbuch NICHT ist:**

âŒ Kein Ersatz fÃ¼r Software-Engineering-Wissen (Clean Code, Design Patterns, etc.)
âŒ Keine "Silver Bullet" die alle Probleme lÃ¶st
âŒ Kein starres Framework (passen Sie es an Ihre BedÃ¼rfnisse an!)
âŒ Keine umfassende AI-Prompt-Engineering-Anleitung
âŒ Kein Projekt-Management-Framework wie Scrum oder Kanban

**Dieses Handbuch IST:**

âœ… Ein **pragmatischer Leitfaden** fÃ¼r Vibe Coding mit professionellen Praktiken
âœ… Eine **bewÃ¤hrte Methodik** aus realen Projekten
âœ… Ein **flexibles Framework** das Sie anpassen kÃ¶nnen
âœ… Eine **Sammlung von Best Practices** fÃ¼r Session-Management, Backup, ADRs, Quality Gates
âœ… Ein **Startpunkt** fÃ¼r erfolgreiche Vibe Coding Projekte

### 1.3 FÃ¼r wen ist dieser Guide?

**Dieser Guide ist fÃ¼r Sie, wenn Sie...**

#### Solo-Entwickler (1 Person)

Sie arbeiten alleine mit einem AI-Assistenten (Claude, GPT, Gemini) und mÃ¶chten:
- âœ… Ihre Projekte erfolgreich zum Abschluss bringen (nicht nur starten!)
- âœ… Nach Unterbrechungen schnell wieder einsteigen
- âœ… Entscheidungen dokumentieren (fÃ¼r Ihr zukÃ¼nftiges Ich)
- âœ… Professionelle Backup-Strategien haben
- âœ… Von "chaotisches Prototyping" zu "strukturierte Entwicklung" upgraden

**AnwendungsfÃ¤lle:** Side-Projects, Freelance-Projekte, Startup-MVPs, Learning-Projects

#### Kleine Teams (2-5 Personen)

Ihr Team arbeitet mit AI-Assistenten und Sie brauchen:
- âœ… Koordinations-Mechanismen (wer arbeitet woran?)
- âœ… Handoff-Protokolle (wie Ã¼bergebe ich an Kollegen?)
- âœ… Shared Context (wie bleibt das Team synchronisiert?)
- âœ… ADR-System (wie dokumentieren wir Team-Entscheidungen?)
- âœ… Code Review Integration (wie reviewen wir AI-generierten Code?)

**AnwendungsfÃ¤lle:** Startup-Teams, Small Agency-Projekte, Open-Source Kollaborationen

#### Mittlere Teams (5-15 Personen)

Ihr Team hat mehrere Squads und Sie benÃ¶tigen:
- âœ… Squad-basierte Session-Management
- âœ… Cross-Team ADRs (Entscheidungen die mehrere Teams betreffen)
- âœ… Onboarding-Prozess fÃ¼r neue Entwickler
- âœ… Quality Gates mit CI/CD Integration
- âœ… Team-Retrospektiven und Wissens-Transfer

**AnwendungsfÃ¤lle:** Scale-ups, Mid-Size Company Projekte, Enterprise Innovation Labs

#### GroÃŸe Teams (15+ Personen)

Ihr Enterprise-Team benÃ¶tigt:
- âœ… Governance-Strukturen fÃ¼r AI-Code-Generierung
- âœ… Compliance-Integration (GDPR, HIPAA, SOC2)
- âœ… Multi-Team Session-Koordination
- âœ… Architecture Review Boards fÃ¼r ADRs
- âœ… Enterprise Backup & Disaster Recovery

**AnwendungsfÃ¤lle:** Enterprise-Projekte, Multi-Product-Plattformen, Regulated Industries

#### Projekt-Typen

Dieser Guide funktioniert fÃ¼r:

**Web-Applikationen:**
- Frontend: React, Vue, Angular, Svelte
- Backend: Node.js, Django, Spring Boot, Laravel, Ruby on Rails
- Full-Stack: Next.js, Remix, SvelteKit

**Mobile-Applikationen:**
- Cross-Platform: React Native, Flutter, Xamarin
- Native: Swift (iOS), Kotlin (Android)

**CLI-Tools:**
- Go (Cobra, urfave/cli)
- Rust (clap, structopt)
- Python (Click, Typer, argparse)
- Node.js (Commander, yargs)

**Desktop-Applikationen:**
- Electron, Tauri, Qt, GTK
- Native: Swift (macOS), C# (Windows)

**Microservices:**
- gRPC, REST APIs, GraphQL
- Go, Rust, Node.js, Java/Spring Cloud

**Embedded Systems:**
- Rust, C, C++ (mit EinschrÃ¤nkungen)

**Datenbanken & Backend:**
- SQL: PostgreSQL, MySQL, SQLite
- NoSQL: MongoDB, Redis, Cassandra

### 1.4 Wie Sie diesen Guide nutzen

#### FÃ¼r Eilige: Quick Start (5 Minuten)

```bash
# 1. Lesen Sie: QUICK_START_DE.md
less QUICK_START_DE.md

# 2. Kopieren Sie Templates
cp templates/project-charter.md mein-projekt/
cp templates/session-context.md mein-projekt/

# 3. Session starten
python scripts/session-management/session-start.py

# 4. Entwickeln â†’ Session beenden â†’ Wiederholen!
```

**â†’ [Zum Quick Start Guide](QUICK_START_DE.md)**

#### FÃ¼r GrÃ¼ndliche: VollstÃ¤ndiger Durchlauf (30-60 Minuten)

**Phase 1: Lesen (30 Min)**
1. Lesen Sie [Teil I: Grundlagen](#teil-i-grundlagen) (diese Sektion)
2. Ãœberfliegen Sie [Teil II: Die 6-Phasen-Architektur](#teil-ii-die-6-phasen-architektur)
3. Entscheiden Sie Ihren [Skalierungs-Modus](#3-skalierungs-leitfaden) (Micro/Klein/Mittel/GroÃŸ)

**Phase 2: Setup (20 Min)**
4. Kopieren Sie relevante [Templates](#teil-v-anhang) fÃ¼r Ihr Projekt
5. Installieren Sie [Scripts](#appendix-a-komplette-script-bibliothek) (optional)
6. Erstellen Sie `project-charter.md` und `tech-stack.md`

**Phase 3: Implementation (10 Min)**
7. Starten Sie Ihre erste Session mit `session-start.py/js/sh`
8. Entwickeln Sie nach [Phase 1: Implementierungsplan](#phase-1-implementierungsplan-exzellenz)
9. Beenden Sie Session mit `session-end.py/js/sh`

#### FÃ¼r Teams: Onboarding (1-2 Stunden)

**Tag 1: Team-Alignment (1h)**
1. **Team-Lesung:** Jeder liest [Teil I](#teil-i-grundlagen) (30 Min)
2. **Diskussion:** Welche Phasen sind fÃ¼r uns relevant? (15 Min)
3. **Entscheidungen:** [Skalierungs-Modus](#3-skalierungs-leitfaden) und Tool-Auswahl (15 Min)

**Tag 2: Setup & Erste Session (1h)**
4. **Gemeinsames Setup:** Templates kopieren, Scripts installieren (20 Min)
5. **Erste Team-Session:** Mit [Phase 2: Session-KontinuitÃ¤t](#phase-2-session-kontinuitÃ¤t--state-management) (30 Min)
6. **Retrospektive:** Was funktionierte? Was anpassen? (10 Min)

#### Referenz-Nutzung: WÃ¤hrend der Entwicklung

**Als Nachschlagewerk:**
- ğŸ” **Suche:** Nutzen Sie Markdown-Anker (`#phase-0-pre-project-foundation`)
- ğŸ“‹ **Checklisten:** [Kapitel 9: Checklisten](#9-checklisten) fÃ¼r konkrete TODOs
- ğŸ› ï¸ **Scripts:** [Appendix A: Script-Bibliothek](#appendix-a-komplette-script-bibliothek)
- ğŸ“Š **Entscheidungen:** [Entscheidungs-Matrizen](decision-matrices/) fÃ¼r Tech-Stack-Wahl

**Typische Fragen wÃ¤hrend Entwicklung:**

| Frage | Antwort in... |
|-------|---------------|
| "Wie starte ich eine Session?" | [Phase 2.3: Session-Lifecycle Scripts](#phase-2-session-kontinuitÃ¤t--state-management) |
| "Welche Sprache soll ich wÃ¤hlen?" | [decision-matrices/language-selection.md](decision-matrices/language-selection.md) |
| "Wie dokumentiere ich eine Entscheidung?" | [Phase 4: ADR-System](#phase-4-decision-logging-adr-system) |
| "Wie setze ich Quality Gates?" | [Phase 5: Quality Gates](#phase-5-quality-gates--verification) |
| "Wie koordiniert sich unser Team?" | [Phase 2.6: Team-Kollaborations-Patterns](#phase-2-session-kontinuitÃ¤t--state-management) |
| "Was mache ich bei Datenverlust?" | [Phase 3: Backup & Recovery](#phase-3-backup--recovery) |

### 1.5 Glossar & Kernkonzepte

Bevor wir tiefer eintauchen, klÃ¤ren wir die wichtigsten Begriffe:

#### Vibe Coding
**Definition:** Intuitives, flow-basiertes Programmieren mit AI-Assistenten, bei dem der Entwickler in natÃ¼rlicher Sprache kommuniziert und die AI Code generiert, erklÃ¤rt, oder refactort.

**Nicht zu verwechseln mit:**
- **Pair Programming:** Zwei Menschen, keine AI
- **Code-Generierung:** Vibe Coding ist mehr als nur Code generieren (auch Architektur, Design, Debugging)
- **No-Code/Low-Code:** Vibe Coding ist full-stack Entwicklung mit AI-UnterstÃ¼tzung

#### Session
**Definition:** Ein zusammenhÃ¤ngender Arbeitsblock (typisch 30 Min â€“ 4 Stunden), in dem ein Entwickler mit einem AI-Assistenten arbeitet. Jede Session hat:
- **session-start:** Beginn mit Kontext-Laden
- **Arbeit:** Entwicklung mit AI-Assistent
- **session-end:** Abschluss mit Handoff-Dokumentation

**Beispiel:** "Ich starte eine Session um Feature X zu implementieren, arbeite 2 Stunden, und beende die Session mit Notizen fÃ¼r mein zukÃ¼nftiges Ich (oder Team-Mitglied)."

#### ADR (Architecture Decision Record)
**Definition:** Ein strukturiertes Dokument, das eine wichtige Architektur-Entscheidung dokumentiert.

**Struktur:**
- **Context:** Warum brauchen wir eine Entscheidung?
- **Decision:** Was haben wir entschieden?
- **Alternatives Considered:** Was haben wir NICHT gewÃ¤hlt und warum?
- **Consequences:** Was sind die positiven/negativen Auswirkungen?

**Beispiel:** "ADR-003: Wir wÃ¤hlen PostgreSQL statt MongoDB, weil unsere Daten relationale IntegritÃ¤t brauchen. Alternative MongoDB wurde abgelehnt wegen fehlender Transaktionen. Konsequenz: Mehr Setup-Aufwand, aber bessere Daten-Konsistenz."

#### Deliverable
**Definition:** Ein konkretes Ergebnis einer Phase (nicht eine vage Aufgabe).

**Gut (Deliverable):**
- âœ… `src/core/auth_manager.py` (180 LOC, OAuth2-Integration)
- âœ… `tests/test_auth.py` (150 LOC, 90% Coverage)
- âœ… `docs/api/authentication.md` (API-Dokumentation)

**Schlecht (Vage Task):**
- âŒ "Implementiere Auth"
- âŒ "Schreibe Tests"
- âŒ "Dokumentiere API"

#### Quality Gate
**Definition:** Ein Checkpoint am Ende jeder Phase, der erfÃ¼llt sein muss bevor die nÃ¤chste Phase beginnt.

**Typische Quality Gates:**
- **Automated:** pytest 0 Failures, Coverage >80%, Linting passed
- **Manual:** Feature funktioniert fÃ¼r 5 Test-Cases, Performance <100ms
- **Documentation:** README aktualisiert, Docstrings vorhanden

**Beispiel:** "Phase 3 Quality Gate: Alle Tests grÃ¼n, Coverage >85%, Performance-Budget eingehalten, ADR-005 geschrieben."

#### Handoff
**Definition:** Strukturierte Informationen am Ende einer Session, die beschreiben:
- Was wurde erreicht?
- Was ist der aktuelle Status?
- Was sind die nÃ¤chsten Schritte?
- Gibt es Blocker?

**Beispiel:**
```yaml
handoff:
  state: "in_progress"
  achieved:
    - Implemented OAuth2 login flow
    - Added unit tests (85% coverage)
  next_steps:
    - Implement refresh token logic
    - Add integration tests
  blockers:
    - Need API credentials for testing
```

#### Phase 0
**Definition:** Die Pre-Project Foundation Phase (typisch 1 Woche fÃ¼r mittlere Projekte), in der alle bekannten LÃ¼cken geschlossen werden BEVOR die Implementation beginnt.

**Deliverables:**
- project-charter.md (Vision, Success Criteria, Out-of-Scope)
- tech-stack.md (Chosen Technologies + Rejected Alternatives)
- Test-Daten (10-20 Golden Samples)
- ADR-001 (Haupt-Architektur-Entscheidung)
- Timeline mit Buffer (+30%)

**Warum wichtig:** Verhindert teure Mid-Course-Korrekturen und gibt allen Beteiligten gemeinsames VerstÃ¤ndnis.

#### Buffer
**Definition:** ZusÃ¤tzliche Zeit (+30% empfohlen), die zu Bottom-up-SchÃ¤tzungen hinzugefÃ¼gt wird, um unbekannte KomplexitÃ¤ten zu absorbieren.

**Beispiel:**
- **Base Estimate:** 10 Wochen (berechnet)
- **Buffer:** +3 Wochen (+30%)
- **Recommended:** 13 Wochen (kommuniziert an Stakeholder)

**Warum wichtig:** Buffer ist NICHT Pessimismus, sondern Best Practice. Stakeholder bevorzugen "Finish Early" > "Late".

#### Stack-Agnostik
**Definition:** Dieser Guide funktioniert mit jeder Programmiersprache, jedem Framework, und jeder Plattform. Wo nÃ¶tig, werden Beispiele in mehreren Sprachen gegeben.

**Beispiel statt "Nutze Python":**
â†’ "WÃ¤hle eine Sprache mit: Type-System, Mature Ecosystem, Team-Expertise. Siehe [decision-matrices/language-selection.md](decision-matrices/language-selection.md)"

#### Drei-Schichten-Architektur (Session-Kontext)
**Definition:** Das Session-Management basiert auf 3 Informations-Ebenen:

```
Layer 1: CONTEXT (WHY)
â”œâ”€â”€ ADRs (Architecture Decision Records)
â”œâ”€â”€ BegrÃ¼ndungen, Alternativen, Konsequenzen
â””â”€â”€ Ã„nderungsfrequenz: Selten

Layer 2: SESSION (WHAT/WHEN)
â”œâ”€â”€ YAML-Sessions mit Handoffs
â”œâ”€â”€ Arbeit, Tasks, Changes, Progress
â””â”€â”€ Ã„nderungsfrequenz: Jede Session

Layer 3: PROJECT (EXISTS)
â”œâ”€â”€ Code, Docs, Config, Database
â”œâ”€â”€ Deliverables, Build-Artefakte
â””â”€â”€ Ã„nderungsfrequenz: Kontinuierlich
```

---

## 2. Die Vibe Coding Methodik: Ãœberblick

### 2.1 Die 6-Phasen-Architektur (Visuell)

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 0: Pre-Project Foundation                                 â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â•‘
â•‘  Dauer: 1 Tag (Micro) | 3-5 Tage (Klein) | 1-2 Wochen (GroÃŸ)    â•‘
â•‘  Ziel: LÃ¼cken schlieÃŸen BEVOR Implementation beginnt              â•‘
â•‘                                                                    â•‘
â•‘  Deliverables:                                                     â•‘
â•‘  â”œâ”€â”€ project-charter.md (Vision, Success Criteria, Scope)         â•‘
â•‘  â”œâ”€â”€ tech-stack.md (Chosen + Rejected Alternatives)               â•‘
â•‘  â”œâ”€â”€ Test-Daten (10-20 Golden Samples)                            â•‘
â•‘  â”œâ”€â”€ ADR-001 (Haupt-Architektur-Entscheidung)                     â•‘
â•‘  â””â”€â”€ Timeline mit Buffer (+30%)                                    â•‘
â•‘                                                                    â•‘
â•‘  Verifikation:                                                     â•‘
â•‘  [ ] Alle Stakeholder aligned                                      â•‘
â•‘  [ ] Tech-Stack dokumentiert mit BegrÃ¼ndungen                      â•‘
â•‘  [ ] Test-Daten vorbereitet                                        â•‘
â•‘  [ ] Risiken identifiziert & mitigiert                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                           â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 1: Implementierungsplan-Exzellenz                         â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â•‘
â•‘  Dauer: 1 Tag (Micro) | 2-5 Tage (Klein) | 1 Woche (GroÃŸ)       â•‘
â•‘  Prinzip: Spezifikation VOR Implementation                        â•‘
â•‘                                                                    â•‘
â•‘  Deliverables:                                                     â•‘
â•‘  â””â”€â”€ IMPLEMENTIERUNGSPLAN.md                                       â•‘
â•‘      â”œâ”€â”€ Phase-Breakdown (konkrete Deliverables)                  â•‘
â•‘      â”œâ”€â”€ Timeline (Bottom-up + Buffer)                             â•‘
â•‘      â”œâ”€â”€ Risk Analysis                                             â•‘
â•‘      â””â”€â”€ Quality Gates pro Phase                                   â•‘
â•‘                                                                    â•‘
â•‘  Verifikation:                                                     â•‘
â•‘  [ ] Jede Phase hat konkrete Deliverables (nicht vage Tasks)      â•‘
â•‘  [ ] Timeline realistisch (mit Buffer)                             â•‘
â•‘  [ ] Quality Gates definiert                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                           â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 2: Session-KontinuitÃ¤t & State-Management                 â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â•‘
â•‘  Dauer: 3-5 Stunden (einmaliges Setup)                            â•‘
â•‘  Prinzip: Projekt-KontinuitÃ¤t ist kein Afterthought               â•‘
â•‘                                                                    â•‘
â•‘  Drei-Schichten-Architektur:                                       â•‘
â•‘  â”œâ”€â”€ Layer 1 (WHY): ADRs â†’ BegrÃ¼ndungen                           â•‘
â•‘  â”œâ”€â”€ Layer 2 (WHAT/WHEN): YAML-Sessions â†’ Handoffs                â•‘
â•‘  â””â”€â”€ Layer 3 (EXISTS): Code/Docs â†’ Deliverables                   â•‘
â•‘                                                                    â•‘
â•‘  Session-Lifecycle:                                                â•‘
â•‘  1. session-start.py/js/sh â†’ LÃ¤dt Kontext                         â•‘
â•‘  2. Arbeit mit AI-Assistent                                        â•‘
â•‘  3. session-end.py/js/sh â†’ Speichert Handoff                      â•‘
â•‘                                                                    â•‘
â•‘  Verifikation:                                                     â•‘
â•‘  [ ] Sessions sind YAML-Schema-valid                               â•‘
â•‘  [ ] Handoff-Informationen vollstÃ¤ndig                             â•‘
â•‘  [ ] Team kann Sessions nahtlos Ã¼bergeben                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                           â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 3: Backup & Recovery                                       â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â•‘
â•‘  Dauer: 2-3 Stunden (einmaliges Setup)                            â•‘
â•‘  Prinzip: Defense in Depth                                         â•‘
â•‘                                                                    â•‘
â•‘  FÃ¼nf-Schichten-Backup-Modell:                                     â•‘
â•‘  â”œâ”€â”€ Layer 1: Git Version Control                                 â•‘
â•‘  â”œâ”€â”€ Layer 2: Lokale Timestamped Backups (rsync/robocopy/rclone) â•‘
â•‘  â”œâ”€â”€ Layer 3: STATUS_TRACKING.md (Human-Readable)                 â•‘
â•‘  â”œâ”€â”€ Layer 4: Cloud Backup (S3, Azure, GCP)                       â•‘
â•‘  â””â”€â”€ Layer 5: Portable Packages                                    â•‘
â•‘                                                                    â•‘
â•‘  ZusÃ¤tzlich:                                                       â•‘
â•‘  â”œâ”€â”€ Secrets Management (git-crypt, SOPS, Vault)                  â•‘
â•‘  â””â”€â”€ Disaster Recovery Drills                                      â•‘
â•‘                                                                    â•‘
â•‘  Verifikation:                                                     â•‘
â•‘  [ ] Backup lÃ¤uft automatisch (tÃ¤glich oder bei session-end)      â•‘
â•‘  [ ] Restore getestet (Recovery-Drill durchgefÃ¼hrt)                â•‘
â•‘  [ ] Secrets NICHT in Backups (oder verschlÃ¼sselt)                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                           â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 4: Decision Logging (ADR-System)                          â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â•‘
â•‘  Dauer: 15-30 Min pro ADR                                          â•‘
â•‘  Prinzip: Architektur-Entscheidungen sind Projekt-Assets          â•‘
â•‘                                                                    â•‘
â•‘  ADR-Lifecycle:                                                    â•‘
â•‘  1. ğŸ”µ Proposed â†’ Diskussion                                       â•‘
â•‘  2. ğŸŸ¢ Accepted â†’ Implementierung                                  â•‘
â•‘  3. ğŸŸ¡ Superseded â†’ Ersetzt durch neueres ADR                      â•‘
â•‘  4. âš« Deprecated â†’ Nicht mehr relevant                             â•‘
â•‘                                                                    â•‘
â•‘  Wann ADR erstellen?                                               â•‘
â•‘  â”œâ”€â”€ Sprach-/Framework-Wahl                                        â•‘
â•‘  â”œâ”€â”€ Architektur-Entscheidungen (Monolith vs Microservices)       â•‘
â•‘  â”œâ”€â”€ Datenbank-Wahl (SQL vs NoSQL)                                â•‘
â•‘  â”œâ”€â”€ Deployment-Strategie (Cloud vs Self-Hosted)                  â•‘
â•‘  â””â”€â”€ Scope-Ã„nderungen (Feature X aus v1.0 entfernen)              â•‘
â•‘                                                                    â•‘
â•‘  Verifikation:                                                     â•‘
â•‘  [ ] Alternatives Considered dokumentiert                          â•‘
â•‘  [ ] Konsequenzen (positiv + negativ) genannt                      â•‘
â•‘  [ ] Team hat ADR reviewed (bei Teams >1)                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                           â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 5: Quality Gates & Verification                           â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â•‘
â•‘  Dauer: 30-60 Min pro Phase (Gate definieren + checken)           â•‘
â•‘  Prinzip: QualitÃ¤t eingebaut, nicht nachtrÃ¤glich geprÃ¼ft          â•‘
â•‘                                                                    â•‘
â•‘  Quality Gate Template (pro Phase):                                â•‘
â•‘  â”œâ”€â”€ Automated:                                                    â•‘
â•‘  â”‚   â”œâ”€â”€ Tests (pytest/Jest/go test/cargo test/JUnit)             â•‘
â•‘  â”‚   â”œâ”€â”€ Coverage >80%                                             â•‘
â•‘  â”‚   â”œâ”€â”€ Linting (flake8/ESLint/golangci-lint/clippy)             â•‘
â•‘  â”‚   â””â”€â”€ Type-Checking (mypy/TypeScript/built-in)                 â•‘
â•‘  â”œâ”€â”€ Manual:                                                       â•‘
â•‘  â”‚   â”œâ”€â”€ Feature funktioniert (5 Test-Cases)                       â•‘
â•‘  â”‚   â”œâ”€â”€ Performance-Budget eingehalten                            â•‘
â•‘  â”‚   â””â”€â”€ UI/UX responsive (kein Freeze)                            â•‘
â•‘  â””â”€â”€ Documentation:                                                â•‘
â•‘      â”œâ”€â”€ README aktualisiert                                       â•‘
â•‘      â”œâ”€â”€ CHANGELOG enthÃ¤lt Eintrag                                 â•‘
â•‘      â””â”€â”€ Docstrings fÃ¼r Ã¶ffentliche APIs                           â•‘
â•‘                                                                    â•‘
â•‘  CI/CD Integration:                                                â•‘
â•‘  â””â”€â”€ GitHub Actions / GitLab CI / Jenkins / CircleCI              â•‘
â•‘                                                                    â•‘
â•‘  Verifikation:                                                     â•‘
â•‘  [ ] Alle Quality Gates grÃ¼n                                       â•‘
â•‘  [ ] Keine Regression in vorherigen Features                       â•‘
â•‘  [ ] CI/CD Pipeline passed (bei CI/CD-Nutzung)                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                           â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 6: Kontinuierliches Lernen                                â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â•‘
â•‘  Dauer: 5 Min pro Session (Retrospektive)                         â•‘
â•‘  Prinzip: Projekte entwickeln sich, PlÃ¤ne auch                     â•‘
â•‘                                                                    â•‘
â•‘  Post-Session Retrospektive:                                       â•‘
â•‘  â”œâ”€â”€ Was lief gut?                                                 â•‘
â•‘  â”œâ”€â”€ Was lief schlecht?                                            â•‘
â•‘  â”œâ”€â”€ Lessons Learned                                               â•‘
â•‘  â””â”€â”€ Action Items fÃ¼r Prozess-Verbesserung                         â•‘
â•‘                                                                    â•‘
â•‘  Team-Retrospektiven (bei Teams):                                  â•‘
â•‘  â”œâ”€â”€ Daily Standup Integration                                     â•‘
â•‘  â”œâ”€â”€ Sprint Retrospectives (alle 2 Wochen)                         â•‘
â•‘  â””â”€â”€ Post-Mortem Analysis (nach Major-Incidents)                   â•‘
â•‘                                                                    â•‘
â•‘  Verifikation:                                                     â•‘
â•‘  [ ] Retrospektive dokumentiert                                    â•‘
â•‘  [ ] Action Items umgesetzt (in nÃ¤chster Session/Sprint)           â•‘
â•‘  [ ] Prozess iterativ verbessert                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### 2.2 10 Kernprinzipien

Diese Prinzipien durchziehen die gesamte Methodik:

#### 1. Spezifikation vor Implementation

âŒ **Falsch:** "Lass uns einfach anfangen und sehen was passiert"
âœ… **Richtig:** "Phase 0 + Phase 1 definieren Vision, Scope, und Implementierungsplan BEVOR Code geschrieben wird"

**Warum:** Mid-Course Chaos tritt auf wenn niemand weiÃŸ was gebaut werden soll. Spezifikation (nicht perfekt, aber gut genug) spart Wochen verschwendeter Arbeit.

**Beispiel:**
```markdown
# BEVOR Implementation:
project-charter.md:
- Vision: "Ein CLI-Tool das Git-Repos analysiert"
- Success Criteria: [ ] Analysiert 100+ Repos in <5 Min
                    [ ] Exportiert CSV/JSON
- Out-of-Scope: âŒ Keine GUI (v1.0)
                âŒ Keine GitHub API Integration (v2.0)
```

#### 2. Iterative Verfeinerung ist erlaubt

âŒ **Falsch:** "Plan v1.0 ist perfekt, keine Ã„nderungen"
âœ… **Richtig:** "Plan v1.0 â†’ v2.0 (Feedback) â†’ v2.1 (Review)"

**Warum:** Projekte entwickeln sich. Neue Erkenntnisse kommen wÃ¤hrend Implementation. Versionen zeigen Lernprozess.

**Beispiel:**
```markdown
IMPLEMENTIERUNGSPLAN.md Version History:

v1.0.0 (2026-01-15): Initial (8 weeks, 6 features)
v2.0.0 (2026-01-22): Expansion (12 weeks, +4 features)
  Reason: User research identified gaps
v2.1.0 (2026-01-31): Refinement (14 weeks, fixed 3 blockers)
  Reason: Technical review identified dependencies
```

#### 3. Pragmatismus Ã¼ber Perfektion

âŒ **Falsch:** "Wir brauchen Alembic weil es Best Practice ist"
âœ… **Richtig:** "Alembic ist Overhead fÃ¼r Desktop-App (5000+ LOC nur fÃ¼r Migrations). Simple SQL Runner reicht."

**Warum:** Over-Engineering tÃ¶tet Projekte. WÃ¤hle Technologien nach **tatsÃ¤chlichem Bedarf**, nicht nach Hype.

**Beispiel:**
```markdown
# tech-stack.md - Abgelehnte Alternativen

| Alternative | Grund der Ablehnung |
|-------------|---------------------|
| Alembic     | Overhead fÃ¼r Desktop-App. Simple SQL + Python Runner reicht. |
| PostgreSQL  | Requires Server. SQLite ist embedded und perfekt fÃ¼r Desktop. |
| Electron    | 200+ MB Bundle. Tauri ist 10Ã— kleiner. |
```

#### 4. QualitÃ¤t einbauen, nicht nachprÃ¼fen

âŒ **Falsch:** "Phase 10: Tests schreiben fÃ¼r alles"
âœ… **Richtig:** "Jede Phase: Tests parallel zu Code, 80% Coverage Gate"

**Warum:** Tests nachtrÃ¤glich zu schreiben ist schmerzhaft und fÃ¼hrt zu untestable Code. Tests parallel = besseres Design.

**Beispiel:**
```markdown
Phase 3: Auth-System (Week 3)
Deliverables:
- src/auth/manager.py (200 LOC)
- tests/test_auth.py (180 LOC) â† Parallel geschrieben!
- Coverage: 92% â† Verified

Quality Gate:
[ ] pytest 0 Failures
[ ] Coverage >80% âœ“ (92%)
[ ] Auth funktioniert fÃ¼r 5 Test-Cases
```

#### 5. Session-KontinuitÃ¤t als First-Class Concern

âŒ **Falsch:** "Wir notieren uns was in Slack/Email"
âœ… **Richtig:** "YAML-Sessions + ADRs + Quick-Start-Kontext"

**Warum:** Context-Loss ist der #1 ProduktivitÃ¤ts-Killer bei Unterbrechungen. Strukturierter Handoff lÃ¶st das.

**Beispiel:**
```yaml
# .continuity/sessions/2026-01-31_session-001.yml
session:
  handoff:
    state: "in_progress"
    achieved:
      - Implemented OAuth2 login
      - Added unit tests (85% coverage)
    next_steps:
      - Implement refresh token logic
      - Add integration tests
    blockers:
      - Need API credentials for testing (ask ops-team)
```

#### 6. Backup-Redundanz ohne Overhead

âŒ **Falsch:** "Git reicht, Backups sind Overhead"
âœ… **Richtig:** "5-Layer-System (Git + Lokal + Cloud + Tracking + Portable)"

**Warum:** Single Point of Failure. Festplatten crashen. Git-Remote versagt. Redundanz rettet Projekte.

**Beispiel:**
```bash
# Automatisches Backup bei session-end
./session-end.sh
â†’ Triggers:
  1. Git commit + push
  2. rsync to local backup (timestamped)
  3. rclone sync to S3 (incremental)
  4. STATUS_TRACKING.md updated

# Recovery nach Festplatten-Crash:
./restore-from-backup.sh 2026-01-31_14-30
â†’ Restored in 5 minutes
```

#### 7. Entscheidungen dokumentieren

âŒ **Falsch:** "Das wissen wir schon"
âœ… **Richtig:** "ADR fÃ¼r jede wichtige Entscheidung"

**Warum:** Nach 3 Monaten: "Warum haben wir X statt Y gewÃ¤hlt?" Ohne ADR: Wiederholte Diskussionen.

**Beispiel:**
```markdown
# ADR-005: Warum React statt Vue?

Context: Frontend-Framework-Wahl fÃ¼r Web-App

Decision: React

Alternatives Considered:
- Vue: âœ… Einfacher, âŒ Kleineres Ecosystem
- Angular: âœ… Enterprise-ready, âŒ Zu heavyweight
- Svelte: âœ… Performant, âŒ Hiring schwierig

Chosen: React
- âœ… GrÃ¶ÃŸtes Ecosystem (Komponenten-Bibliotheken)
- âœ… Team hat React-Expertise
- âŒ Komplexere State-Management

Consequences:
+ Schnellere Entwicklung (viele fertige Komponenten)
- Mehr Boilerplate als Vue
```

#### 8. Transparente Buffer-Strategie

âŒ **Falsch:** "30 Wochen, definitiv"
âœ… **Richtig:** "30 Wochen base, 39 Wochen recommended (+30% buffer)"

**Warum:** Buffer ist NICHT Pessimismus, sondern Best Practice. Stakeholder bevorzugen "Finish Early" > "Late".

**Beispiel:**
```markdown
## Timeline Estimates

Approach: Bottom-up, per-phase calculation
Realism: Based on similar projects
Buffer: Industry-standard +30%

Base Estimate: 10 weeks (calculated)
Recommended (With Buffer): 13 weeks (~3 months)

Rationale:
- Unbekannte KomplexitÃ¤ten werden auftauchen
- Buffer ist NICHT Pessimismus, sondern Best Practice
- Stakeholder bevorzugen "Finish Early" > "Late"
```

#### 9. Team-Skalierung explizit handhaben

âŒ **Falsch:** "Wir sind jetzt 5 Leute, machen aber weiter wie Solo"
âœ… **Richtig:** "Team-Patterns fÃ¼r Multi-Developer Sessions, ADR-Konflikt-AuflÃ¶sung, Async Handoffs"

**Warum:** Solo-Patterns funktionieren NICHT fÃ¼r Teams. Ohne explizite Team-Koordination: Chaos.

**Beispiel:**
```yaml
# Multi-Developer Session Naming
sessions/
â”œâ”€â”€ 2026-01-31_dev-alice_001.yml  # Alice's Session
â”œâ”€â”€ 2026-01-31_dev-bob_001.yml    # Bob's Session
â””â”€â”€ 2026-01-31_dev-carol_001.yml  # Carol's Session

# Handoff Protocol: Next Developer explizit genannt
handoff:
  next_developer: "bob"
  context_for_bob:
    - "I started auth-system refactor"
    - "See ADR-008 for decision rationale"
    - "Tests are failing, need your help debugging"
```

#### 10. CI/CD als Quality Gate Enforcer

âŒ **Falsch:** "Wir checken Quality Gates manuell vor Merge"
âœ… **Richtig:** "GitHub Actions / GitLab CI checkt automatisch bei jedem Push"

**Warum:** Menschen vergessen. CI/CD vergisst nie. Automatisierung = Konsistenz.

**Beispiel:**
```yaml
# .github/workflows/quality-gates.yml
name: Quality Gates
on: [push, pull_request]

jobs:
  quality-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      # Session YAML Validation
      - name: Validate Sessions
        run: python scripts/quality/validate-session.py

      # Tests
      - name: Run Tests
        run: pytest

      # Coverage Check (Fail if < 80%)
      - name: Check Coverage
        run: pytest --cov --cov-fail-under=80

      # Linting
      - name: Lint Code
        run: flake8 src/
```

### 2.3 Erfolgsmetriken

**Wie messen wir, ob Vibe Coding mit diesem Guide erfolgreich ist?**

#### Projekt-Level Metriken

| Metrik | Ohne Guide (typisch) | Mit Guide (Ziel) |
|--------|----------------------|------------------|
| **Projekt-Abschlussrate** | 20-30% | >80% |
| **Mid-Course Pivot-Rate** | 60-80% | <20% |
| **Context-Loss-VorfÃ¤lle** | 5-10 pro Projekt | <2 pro Projekt |
| **Datenverlust-VorfÃ¤lle** | 10-20% Projekte | <1% Projekte |
| **Time-to-Implementation** | 2-4 Wochen (Chaos-Start) | 1 Woche (Phase 0) + sauberer Start |
| **Technical Debt** | Hoch (nachtrÃ¤gliche Tests) | Niedrig (Tests parallel) |

#### Session-Level Metriken

| Metrik | Ohne Guide | Mit Guide |
|--------|-----------|-----------|
| **Session-Start-Zeit** | 15-30 Min (Context-Suche) | <5 Min (YAML-Laden) |
| **Session-ProduktivitÃ¤t** | 40-60% (Unterbrechungen) | 70-90% (Flow) |
| **Handoff-QualitÃ¤t** | Vage Notizen | Strukturiert (YAML) |
| **Onboarding-Zeit (neue Member)** | 2-3 Wochen | 3-5 Tage |

#### Team-Level Metriken

| Metrik | Ohne Guide | Mit Guide |
|--------|-----------|-----------|
| **Team-Alignment** | Niedrig (jeder sein "Vibe") | Hoch (Shared ADRs) |
| **Wiederholte Diskussionen** | 10-20 pro Projekt | <3 pro Projekt |
| **Merge-Konflikt-Rate** | 30-50% PRs | <10% PRs |
| **Code Review Zeit** | 2-5 Tage | <1 Tag |

#### Quality-Level Metriken

| Metrik | Ohne Guide | Mit Guide |
|--------|-----------|-----------|
| **Test Coverage** | 20-40% | >80% |
| **Bug-Escape-Rate** | Hoch (keine Quality Gates) | Niedrig (Gates pro Phase) |
| **Regression-Rate** | 30-50% Releases | <10% Releases |
| **Production-Incidents** | 5-10 pro Monat | <2 pro Monat |

**Wie Sie Ihre Metriken tracken:**

```markdown
# QUALITY_METRICS.md

## Project: MeinProjekt
## Start: 2026-01-15
## Current Phase: Phase 5

### Erfolgsmetriken (Updated: 2026-01-31)

#### Projekt-Level:
- [x] Phase 0 completed (1 week)
- [x] IMPLEMENTIERUNGSPLAN.md v2.1 (iterative refinement)
- [ ] Mid-Course Pivot: 0 (Ziel: <2)
- [ ] Context-Loss Incidents: 1 (Ziel: <2)

#### Quality-Level:
- Test Coverage: 87% (Ziel: >80%) âœ“
- Bug-Escape-Rate: 5% (Ziel: <10%) âœ“
- CI/CD Pipeline: GrÃ¼n (15 consecutive passes)

#### Session-Level:
- Avg Session-Start-Zeit: 3 Min (Ziel: <5 Min) âœ“
- Sessions mit vollstÃ¤ndigem Handoff: 12/12 (100%)
- Team-Onboarding-Zeit (letzte 2 members): 4 Tage (Ziel: <5 Tage) âœ“
```

### 2.4 HÃ¤ufige Anti-Patterns

**Diese Patterns fÃ¼hren zum Scheitern â€“ vermeiden Sie sie!**

#### Anti-Pattern 1: "Vibe Coding ohne Plan"

**Problem:**
- Keine klare Vision
- Features werden zufÃ¤llig implementiert
- Keine Priorisierung
- Nach 3 Wochen: "Was bauen wir eigentlich?"

**Symptome:**
- Keine project-charter.md
- Kein IMPLEMENTIERUNGSPLAN.md
- Jede Session hat ein zufÃ¤lliges Goal
- Features werden halb implementiert, dann vergessen

**LÃ¶sung:**
- Phase 0 mit project-charter.md
- IMPLEMENTIERUNGSPLAN.md mit Phase-Breakdown
- Jede Session hat konkretes Goal aus Plan

**Beispiel (Gut):**
```markdown
# project-charter.md
Vision: Ein CLI-Tool das Git-Repos analysiert
Success Criteria:
- [ ] Analysiert 100+ Repos in <5 Min
- [ ] Exportiert CSV/JSON
- [ ] 90% User-Zufriedenheit

# IMPLEMENTIERUNGSPLAN.md
Phase 1: Core (Week 1) â†’ src/core/analyzer.py (200 LOC)
Phase 2: Export (Week 2) â†’ src/export/csv.py (150 LOC)
...
```

#### Anti-Pattern 2: "Context-Loss bei Unterbrechungen"

**Problem:**
- Nach Pause: "Was habe ich zuletzt gemacht?"
- Keine Handoff-Informationen
- Doppelte Arbeit
- Inkonsistente Implementierungen

**Symptome:**
- Keine Session-Tracking
- Notizen in Slack/Email verstreut
- AI-Assistent hat keinen persistenten State
- Teammitglieder fragen stÃ¤ndig "Was ist Status?"

**LÃ¶sung:**
- Session-Framework mit Handoff
- YAML-Sessions mit strukturierten Informationen
- Letzte Session YAML lesen bei session-start

**Beispiel (Gut):**
```yaml
# sessions/2026-01-31_session-003.yml
session:
  handoff:
    achieved:
      - Implemented CSV export
      - Added unit tests (90% coverage)
    current_status:
      - CSV works for 50+ repos tested
      - JSON export next
    next_steps:
      - Implement JSON export (similar to CSV)
      - Add integration test with real Git repos
    blockers:
      - None currently
```

#### Anti-Pattern 3: "Wir schreiben Tests spÃ¤ter"

**Problem:**
- Tests werden nie geschrieben
- Code ist untestable (tight coupling)
- Regression-Bugs hÃ¤ufig
- Refactoring unmÃ¶glich (Angst etwas zu brechen)

**Symptome:**
- Coverage <20%
- Keine Tests in Deliverables
- "Phase 10: Testing" im Plan
- HÃ¤ufige Production-Incidents

**LÃ¶sung:**
- Tests parallel zu Code
- Quality Gates pro Phase (Coverage >80%)
- Test-driven oder Test-alongside Development

**Beispiel (Gut):**
```markdown
Phase 3: Auth-System (Week 3)
Deliverables:
- src/auth/manager.py (200 LOC)
- tests/test_auth.py (180 LOC) â† Parallel!
- tests/test_auth_integration.py (120 LOC)

Quality Gate:
[ ] pytest 0 Failures âœ“
[ ] Coverage >80% âœ“ (92%)
[ ] Auth funktioniert fÃ¼r 5 TestfÃ¤lle âœ“
```

#### Anti-Pattern 4: "Entscheidungen im Nebel"

**Problem:**
- Nach Monaten: "Warum haben wir X so gemacht?"
- Keine Dokumentation von Alternativen
- Wiederholte Diskussionen
- Neue Teammitglieder verstehen Architektur nicht

**Symptome:**
- Keine ADRs
- Architektur-Entscheidungen nur in Code-Comments
- Team fragt stÃ¤ndig "Warum nicht Y?"
- Tech-Stack-Wahl nicht begrÃ¼ndet

**LÃ¶sung:**
- ADR fÃ¼r jede wichtige Entscheidung
- Alternatives Considered dokumentieren
- ADRs verlinkt mit Sessions

**Beispiel (Gut):**
```markdown
# ADR-003: Warum SQLite statt PostgreSQL?

Context: Desktop-App braucht lokale Datenbank

Decision: SQLite

Alternatives Considered:
- PostgreSQL: âœ… Robust, âŒ Requires Server (user muss installieren)
- MySQL: âœ… Bekannt, âŒ Ebenfalls Server-Requirement
- JSON-Files: âœ… Simple, âŒ Keine Transaktionen, schlechte Performance

Chosen: SQLite
- âœ… Embedded (keine Installation)
- âœ… Zero-Config
- âœ… Transaktionen
- âŒ Nicht fÃ¼r Multi-User (akzeptabel fÃ¼r Desktop-App)

Consequences:
+ Simple Deployment
+ Keine Server-Dependencies
- Migration zu PostgreSQL spÃ¤ter schwieriger (akzeptiert)
```

#### Anti-Pattern 5: "Ein Backup reicht"

**Problem:**
- Single Point of Failure
- Festplatten-Crash â†’ Projekt verloren
- Git ohne Remote â†’ kein Backup
- Session-State nicht gesichert

**Symptome:**
- Nur Git (kein Remote)
- Oder: Nur lokale Backups (keine Cloud)
- Keine Backup-Automation
- Restore nie getestet

**LÃ¶sung:**
- 5-Layer-Backup-System
- RegelmÃ¤ÃŸige Restore-Tests
- Automatisierung via session-end.sh

**Beispiel (Gut):**
```bash
# Automatisches Backup-System

Layer 1: Git Version Control
â†’ git push origin main (bei session-end)

Layer 2: Lokale Timestamped Backups
â†’ rsync -a --link-dest=latest project/ backups/2026-01-31_14-30/

Layer 3: Cloud Backup
â†’ rclone sync project/ s3:my-bucket/project-backups/

Layer 4: STATUS_TRACKING.md
â†’ Human-readable Recovery-Guide

Layer 5: Portable Package
â†’ tar.gz fÃ¼r Archiv (bei Milestones)
```

#### Anti-Pattern 6: "Solo-Patterns fÃ¼r Teams verwenden"

**Problem:**
- Team wÃ¤chst von 1 â†’ 5 Personen
- Aber: Workflows bleiben Solo-fokussiert
- Keine Team-Koordination
- Merge-Konflikte, doppelte Arbeit

**Symptome:**
- Sessions ohne Developer-Name
- Keine explizite Handoff an Kollegen
- ADRs werden individual entschieden
- Keine Team-Retrospektiven

**LÃ¶sung:**
- Team-Patterns fÃ¼r Multi-Developer Sessions
- ADR-Konflikt-AuflÃ¶sung (wenn 2+ Proposals)
- Async Handoffs Ã¼ber Zeitzonen

**Beispiel (Gut):**
```yaml
# sessions/2026-01-31_dev-alice_002.yml
session:
  operator:
    type: "human"
    identity: "alice@company.com"
  handoff:
    next_developer: "bob@company.com"
    context_for_next:
      - "Started feature-X, see branch feature/X"
      - "Tests failing, need help debugging auth-issue"
      - "See ADR-009 for decision rationale"
    blockers:
      - "Need Bob's review on PR #42"
```

#### Anti-Pattern 7: "Keine CI/CD â†’ Manuelle Quality Checks"

**Problem:**
- Quality Gates werden vergessen
- Inconsistent enforcement
- Menschliche Fehler
- Code mit Bugs merged

**Symptome:**
- Keine CI/CD Pipeline
- "Bitte prÃ¼fe Tests vor Merge" â†’ wird vergessen
- Coverage sinkt kontinuierlich
- Production-Bugs hÃ¤ufig

**LÃ¶sung:**
- CI/CD mit automatischen Quality Gates
- Pre-Merge Checks (GitHub Actions / GitLab CI)
- Coverage-Enforcement (Fail if <80%)

**Beispiel (Gut):**
```yaml
# .github/workflows/pr-quality-gates.yml
name: PR Quality Gates
on: pull_request

jobs:
  quality:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run Tests
        run: pytest --cov --cov-fail-under=80
      - name: Lint
        run: flake8 src/
      - name: Type Check
        run: mypy src/
      - name: Validate Sessions
        run: python scripts/quality/validate-session.py

# â†’ Merge nur mÃ¶glich wenn alle Checks grÃ¼n
```

---

## 3. Skalierungs-Leitfaden

**Ein Guide der NICHT skaliert, ist nutzlos.**

Dieses Kapitel zeigt, wie Sie die 6-Phasen-Methodik an Ihre Projekt-GrÃ¶ÃŸe, Team-GrÃ¶ÃŸe, und Projekt-Typ anpassen.

### 3.1 Skalierung nach ProjektgrÃ¶ÃŸe

#### Micro-Projekte (1-2 Wochen)

**Charakteristika:**
- Solo-Entwickler oder Pair
- Klare, begrenzte Scope
- Proof-of-Concept oder kleines Tool
- 500-2000 LOC

**Anwendungsbeispiele:**
- CLI-Tool fÃ¼r lokale Dateiverarbeitung
- Landing-Page fÃ¼r Event
- Automation-Script fÃ¼r Workflow
- Quick-Prototype fÃ¼r Ideen-Validierung

**Simplifikationen:**

| Phase | Standard | Micro-Version |
|-------|----------|---------------|
| **Phase 0** | 1 Woche | **1 Tag** |
| | project-charter.md (2 Seiten) | project-charter.md (1 Seite, nur Vision + Success Criteria) |
| | tech-stack.md (mit Alternativen) | tech-stack.md (nur Chosen, keine Alternativen) |
| | 10-20 Test-Daten | 3-5 Test-Daten |
| | ADR-001 (Architektur) | Optional (nur bei kritischer Entscheidung) |
| **Phase 1** | 2-5 Tage | **Halber Tag** |
| | IMPLEMENTIERUNGSPLAN.md (10 Phasen) | Kombiniere mit project-charter.md (3 Phasen) |
| | Detaillierte LOC-SchÃ¤tzungen | Grobe SchÃ¤tzungen (Small/Medium/Large) |
| **Phase 2** | YAML-Sessions (vollstÃ¤ndig) | Vereinfachte YAML-Sessions (5 Felder) |
| **Phase 3** | 5-Layer Backup | 2-Layer (Git + 1 Cloud Backup) |
| **Phase 4** | ADRs fÃ¼r alle Entscheidungen | Nur bei kritischen Architektur-Entscheidungen |
| **Phase 5** | Quality Gates pro Phase | Basic Linting + manuelle Tests |
| **Phase 6** | Retrospektive pro Session | Optional (nur bei Problemen) |

**Beispiel:** CLI-Tool in Go (1 Woche)

```markdown
# project-charter.md (Micro-Version)

## Vision
Ein CLI-Tool das Git-Repos nach TODOs scannt und CSV exportiert

## Success Criteria
- [ ] Scannt 100+ Repos in <1 Min
- [ ] Exportiert CSV mit TODO-Liste
- [ ] Funktioniert auf Mac/Linux/Windows

## Out-of-Scope (v1.0)
- âŒ Keine GUI
- âŒ Keine GitHub API Integration
- âŒ Kein Config-File (nur CLI-Flags)

## Timeline
- Base: 4 Tage
- With Buffer (+30%): 5-6 Tage

## Tech-Stack
- Language: Go (schnell, cross-platform)
- Libraries: cobra (CLI), filepath (Datei-Traversal)

## Implementation-Phasen
Phase 1 (Day 1-2): Core Scanner
Phase 2 (Day 3): CSV Export
Phase 3 (Day 4): Testing & Polish

## Quality Gates
- go test passes
- Funktioniert fÃ¼r 3 Test-Repos
- README mit Installationsanleitung
```

**Session-Lifecycle (Vereinfacht):**

```bash
# Session-Start (vereinfacht)
echo "Starting session: $(date)" >> .sessions.log
git status  # Quick check

# [WORK]

# Session-End (vereinfacht)
echo "Ending session: $(date)" >> .sessions.log
echo "Achieved: Implemented CSV export" >> .sessions.log
git add . && git commit -m "Implement CSV export"
git push
rclone sync . s3:my-bucket/todo-scanner/  # Cloud backup
```

---

#### Kleine Projekte (2-6 Wochen)

**Charakteristika:**
- Solo oder 2-3 Entwickler
- Klar definierter Scope
- MVP oder kleines Produkt-Feature
- 2.000-10.000 LOC

**Anwendungsbeispiele:**
- Web-Dashboard fÃ¼r Analytics
- Mobile App MVP (React Native)
- REST API mit 10-20 Endpoints
- Desktop-Utility mit UI

**Standard Vibe Coding (wie im Guide beschrieben):**

| Phase | Empfehlung |
|-------|------------|
| **Phase 0** | **3-5 Tage** (volle Tiefe) |
| **Phase 1** | **2-5 Tage** (IMPLEMENTIERUNGSPLAN.md mit 3-6 Phasen) |
| **Phase 2** | **Volle YAML-Sessions** mit Handoff |
| **Phase 3** | **3-Layer Backup** (Git + lokale Backups + Cloud) |
| **Phase 4** | **ADRs fÃ¼r wichtige Entscheidungen** (~3-5 total) |
| **Phase 5** | **Automatisierte Quality Gates** pro Phase |
| **Phase 6** | **Retrospektive** pro Session (5 Min) |

**Beispiel:** Web-Dashboard mit Next.js (4 Wochen)

```markdown
# project-charter.md

## Vision
Ein Web-Dashboard das GitHub-Repo-Statistiken visualisiert

## Success Criteria
- [ ] Zeigt Commits, Issues, PRs fÃ¼r 10+ Repos
- [ ] Responsive Design (Desktop + Mobile)
- [ ] LÃ¤dt in <2 Sekunden
- [ ] 90% Lighthouse Score

## Out-of-Scope (v1.0)
- âŒ Keine Multi-User-Auth (v2.0)
- âŒ Keine Echtzeit-Updates (v2.0)
- âŒ Keine Custom Dashboards (v2.0)

## Timeline
- Base Estimate: 4 weeks (28 days)
- With Buffer (+30%): 5-6 weeks (~6 weeks = 42 days)

## Tech-Stack
- Frontend: Next.js 14, React, Tailwind CSS
- Backend: Next.js API Routes
- Database: SQLite (embedded)
- Deployment: Vercel

# IMPLEMENTIERUNGSPLAN.md

Phase 1: Foundation (Week 1)
â”œâ”€â”€ Project setup (Next.js, Tailwind)
â”œâ”€â”€ Database schema (SQLite)
â””â”€â”€ GitHub API integration

Phase 2: Core Features (Week 2)
â”œâ”€â”€ Repo-Stats fetching
â”œâ”€â”€ Data visualization (charts)
â””â”€â”€ Responsive layout

Phase 3: Polish (Week 3)
â”œâ”€â”€ Performance optimization
â”œâ”€â”€ Error handling
â””â”€â”€ Unit + integration tests

Phase 4: Deployment (Week 4)
â”œâ”€â”€ Vercel deployment
â”œâ”€â”€ Production testing
â””â”€â”€ Documentation
```

**Session-Management (Standard):**

```yaml
# sessions/2026-01-31_session-005.yml
session:
  id: "2026-01-31_session-005"
  start_time: "2026-01-31T14:00:00Z"
  end_time: "2026-01-31T16:30:00Z"
  duration_minutes: 150
  context:
    type: "implementation"
    phase: "Phase 2: Core Features"
    goal: "Implement GitHub API integration"
  handoff:
    state: "completed"
    achieved:
      - "GitHub API OAuth flow working"
      - "Fetch repo stats (commits, issues, PRs)"
      - "Unit tests (85% coverage)"
    next_steps:
      - "Implement data visualization"
      - "Add caching layer (reduce API calls)"
    blockers: []
  metrics:
    commits: 8
    lines_added: 450
    lines_removed: 120
git:
  branch: "feature/github-api"
  commit_hash: "a3f7d92"
  uncommitted_changes: false
```

---

#### Mittlere Projekte (2-4 Monate)

**Charakteristika:**
- 2-5 Entwickler (oder mehr)
- Komplexere Architektur (Microservices, Multi-Layer)
- Produkt mit mehreren Features
- 10.000-50.000 LOC

**Anwendungsbeispiele:**
- SaaS-Plattform MVP
- E-Commerce-Website
- Mobile App mit Backend
- Data-Processing Pipeline

**Enhancements Ã¼ber "Klein":**

| Phase | Klein (2-6 Wochen) | Mittel (2-4 Monate) |
|-------|-------------------|---------------------|
| **Phase 0** | 3-5 Tage | **1-2 Wochen** (tiefere Risiko-Analyse) |
| **Phase 1** | 2-5 Tage | **1 Woche** (10-15 Phasen, Milestone-Planning) |
| **Phase 2** | YAML-Sessions | YAML + **Team-Session-Patterns** (Multi-Developer) |
| **Phase 3** | 3-Layer Backup | **4-Layer Backup** (+ Disaster Recovery Drills) |
| **Phase 4** | ~3-5 ADRs | **~10-15 ADRs** (mehr Architektur-Entscheidungen) |
| **Phase 5** | Basic CI/CD | **VollstÃ¤ndige CI/CD Pipeline** (GitHub Actions / GitLab) |
| **Phase 6** | Retrospektive pro Session | **Sprint Retrospectives** (alle 2 Wochen) |

**ZusÃ¤tzliche Praktiken:**

1. **Milestone-Planning:**
   ```markdown
   Milestone 1 (Week 4): Core Backend
   Milestone 2 (Week 8): Frontend MVP
   Milestone 3 (Week 12): Beta Release
   ```

2. **Team-Koordination:**
   - Weekly Team-Sync (1h)
   - ADR-Review-Meetings (30 Min bei neuen ADRs)
   - Pair/Mob Programming fÃ¼r kritische Features

3. **CI/CD Integration:**
   ```yaml
   # .github/workflows/ci.yml
   on: [push, pull_request]
   jobs:
     backend-tests:
       runs-on: ubuntu-latest
       steps:
         - run: pytest backend/
         - run: pytest --cov --cov-fail-under=80
     frontend-tests:
       runs-on: ubuntu-latest
       steps:
         - run: npm test
         - run: npm run lint
   ```

4. **Quality Metrics Dashboard:**
   ```markdown
   # QUALITY_METRICS.md (auto-generated von CI/CD)

   ## Current Phase: Phase 7 (Week 7)

   ### Code Quality
   - Test Coverage: 84% (Target: >80%) âœ“
   - Linting Errors: 0
   - Type Errors: 0

   ### Performance
   - Backend Response Time (P95): 120ms (Target: <200ms) âœ“
   - Frontend Load Time: 1.8s (Target: <2s) âœ“

   ### Team Metrics
   - Open PRs: 3
   - Avg PR Review Time: 18h (Target: <24h) âœ“
   - ADRs Created: 12
   ```

**Beispiel:** SaaS-Plattform MVP (3 Monate)

```markdown
# project-charter.md

## Vision
Eine SaaS-Plattform fÃ¼r Team-Kollaboration mit AI-Assistenz

## Success Criteria
- [ ] Multi-User Auth mit Teams
- [ ] Real-time Collaboration (WebSockets)
- [ ] AI-Chat-Integration (Claude/GPT)
- [ ] Payment-Integration (Stripe)
- [ ] 99% Uptime (monitored)

## Timeline
- Base: 10 weeks
- With Buffer (+30%): 13 weeks (~3 months)

## Tech-Stack
- Frontend: Next.js, React, Tailwind, Zustand
- Backend: Node.js, Fastify, Prisma, PostgreSQL
- Infrastructure: AWS (EC2, RDS, S3), Docker, Kubernetes
- AI: Anthropic API (Claude), OpenAI API

# IMPLEMENTIERUNGSPLAN.md

Phase 1: Infrastructure (Week 1)
Phase 2: Auth & Teams (Week 2-3)
Phase 3: Real-time Collab (Week 4-5)
Phase 4: AI Integration (Week 6-7)
Phase 5: Payment (Week 8)
Phase 6: Testing & Optimization (Week 9)
Phase 7: Beta Deployment (Week 10)
```

---

#### GroÃŸe Projekte (4-6+ Monate)

**Charakteristika:**
- 5-20+ Entwickler (mehrere Teams/Squads)
- Enterprise-Grade Architektur
- Multi-Produkt oder Plattform
- 50.000-200.000+ LOC
- Compliance-Anforderungen (GDPR, HIPAA, SOC2)

**Anwendungsbeispiele:**
- Enterprise SaaS-Plattform
- Multi-Tenant Microservices-Architektur
- Fintech-Anwendung (reguliert)
- Healthcare-Plattform (HIPAA)

**Enterprise-Enhancements:**

| Aspekt | Mittel (2-4 Monate) | GroÃŸ (4-6+ Monate) |
|--------|---------------------|-------------------|
| **Phase 0** | 1-2 Wochen | **2-3 Wochen** (inkl. Prototyping-Phase) |
| **Planning** | 10-15 Phasen | **Quarterly Planning** (OKRs, Roadmaps) |
| **Team-Struktur** | 2-5 Entwickler | **Multi-Squad** (5-10 Squads, je 3-5 Entwickler) |
| **ADRs** | ~10-15 | **20-50+ ADRs** (Architecture Review Board) |
| **CI/CD** | VollstÃ¤ndig | **Enterprise CI/CD** (Multi-Environment, Canary, Blue-Green) |
| **Backup** | 4-Layer | **5-Layer + DR Drills** (wÃ¶chentlich/monatlich) |
| **Compliance** | Optional | **Mandatory** (GDPR, HIPAA, SOC2 Checklists) |
| **Security** | Basic | **Security Audits, Pentesting, SAST/DAST** |

**ZusÃ¤tzliche Enterprise-Praktiken:**

1. **Architecture Review Board (ARB):**
   - ADRs mÃ¼ssen von ARB approved werden (2-3 Senior Architects)
   - Bi-weekly ARB-Meetings
   - Kritische ADRs brauchen Majority-Vote

2. **Multi-Squad Koordination:**
   ```markdown
   # Team-Struktur

   Squad 1: Frontend (5 Entwickler)
   â”œâ”€â”€ Lead: Alice
   â””â”€â”€ Focus: Web-UI, Mobile-UI

   Squad 2: Backend (5 Entwickler)
   â”œâ”€â”€ Lead: Bob
   â””â”€â”€ Focus: APIs, Microservices

   Squad 3: Platform (4 Entwickler)
   â”œâ”€â”€ Lead: Carol
   â””â”€â”€ Focus: Infrastructure, DevOps, Monitoring

   Cross-Squad Rituals:
   - Weekly All-Hands (1h)
   - Monthly Retros (2h)
   - Quarterly Planning (1 Tag)
   ```

3. **Compliance Integration:**
   ```markdown
   # ADR-025: GDPR Data Retention Policy

   Context: EU-User Data muss nach GDPR verwaltet werden

   Decision:
   - User data deletion nach 30 Tagen (upon request)
   - Logs anonymized nach 90 Tagen
   - Backups verschlÃ¼sselt (AES-256)

   Consequences:
   + GDPR-compliant
   - Mehr Implementierungs-Aufwand (2 Wochen)

   Verification:
   [ ] GDPR-Checkliste completed
   [ ] External Audit passed
   ```

4. **Disaster Recovery (DR) Drills:**
   ```bash
   # Monatlicher DR-Drill

   # 1. Simulate Disaster (Datenbank-Crash)
   kubectl delete pod postgres-0

   # 2. Restore from Backup (Layer 4: Cloud)
   ./scripts/restore-from-s3.sh 2026-01-31_12-00

   # 3. Verify Data Integrity
   ./scripts/verify-db-checksums.sh

   # 4. Measure RTO/RPO
   Recovery Time Objective (RTO): 15 minutes (Target: <30 Min) âœ“
   Recovery Point Objective (RPO): 0 data loss (Target: <1h) âœ“

   # 5. Document Lessons Learned
   â†’ Update RUNBOOK.md
   ```

**Beispiel:** Enterprise SaaS-Plattform (6 Monate)

```markdown
# project-charter.md (Enterprise-Version)

## Vision
Eine Multi-Tenant SaaS-Plattform fÃ¼r Enterprise-Kollaboration

## Success Criteria
- [ ] 10.000+ concurrent users
- [ ] 99.95% Uptime SLA
- [ ] SOC2 Type II compliant
- [ ] <200ms response time (P95)
- [ ] Multi-region deployment (US, EU, APAC)

## Timeline
- Base: 20 weeks
- With Buffer (+30%): 26 weeks (~6 months)

## Tech-Stack
- Frontend: Next.js, React, Zustand, Tailwind
- Backend: Go (gRPC), Node.js (REST APIs)
- Database: PostgreSQL (Citus for sharding), Redis (caching)
- Infrastructure: AWS, Kubernetes, Terraform, ArgoCD
- Monitoring: Prometheus, Grafana, Datadog
- Security: Vault (secrets), WAF, SIEM

## Quarterly Roadmap

Q1 (Month 1-3):
- MVP Core Features (Auth, Teams, Collab)
- Infrastructure Setup (K8s, Multi-Region)
- Security Baseline (OWASP Top 10)

Q2 (Month 4-6):
- Advanced Features (AI, Analytics)
- SOC2 Compliance (Audits, Policies)
- Performance Optimization (Caching, CDN)
```

---

### 3.2 Skalierung nach TeamgrÃ¶ÃŸe

#### Solo-Entwickler (1 Person)

**Simplifikationen:**
- Keine Team-Koordination nÃ¶tig
- Session-YAML ohne `operator.identity` (optional)
- ADRs fÃ¼r eigenes zukÃ¼nftiges Ich (nicht fÃ¼r Team-Review)
- Schnellere Entscheidungen (keine Abstimmung)

**Empfohlene Praktiken:**
- âœ… YAML-Sessions (fÃ¼r eigene KontinuitÃ¤t)
- âœ… ADRs (fÃ¼r "Warum habe ICH das so gemacht?")
- âœ… Backup-System (5-Layer, vollautomatisiert)
- âœ… Quality Gates (selbst-enforced)
- âš ï¸ Team-Patterns: Skip (nicht relevant)

**Session-Workflow:**

```bash
# Morgens: Session starten
./session-start.sh implementation "Implement feature X"

# [2-4 Stunden Arbeit mit AI-Assistent]

# Nachmittags: Session beenden
./session-end.sh
â†’ Handoff fÃ¼r mein zukÃ¼nftiges Ich:
  "Achieved: Feature X 80% done
   Next: Add tests, then deploy"

# Automatisches Backup
â†’ Git push
â†’ rclone sync to S3
```

**Typischer Tagesablauf:**

```
09:00 - session-start.sh
       â”œâ”€â”€ Lese letzte Session-YAML
       â””â”€â”€ Goal: Implement OAuth flow

09:05-12:00 - Entwicklung mit Claude
       â”œâ”€â”€ Implementiere OAuth
       â”œâ”€â”€ Schreibe Tests parallel
       â””â”€â”€ Quick Manual Testing

12:00 - session-end.sh
       â”œâ”€â”€ Handoff: "OAuth 90% done, missing refresh tokens"
       â”œâ”€â”€ Git commit + push
       â””â”€â”€ Backup to S3

14:00 - session-start.sh
       â””â”€â”€ Goal: Finish OAuth + Add integration tests

14:05-17:00 - Entwicklung

17:00 - session-end.sh
       â”œâ”€â”€ Handoff: "OAuth complete, 92% coverage, deployed to staging"
       â”œâ”€â”€ ADR-007 created: "Why OAuth2 not SAML"
       â””â”€â”€ Backup to S3
```

---

#### Kleine Teams (2-5 Personen)

**Neue Herausforderungen:**
- Wer arbeitet woran? (Koordination)
- Wie Ã¼bergebe ich an Kollegen? (Handoff)
- Wie synchronisieren wir Context? (Shared Docs)
- Wie reviewen wir AI-generierten Code? (Code Review)

**Empfohlene Praktiken:**
- âœ… Multi-Developer Session-Naming (`dev-alice_001.yml`)
- âœ… Explizite Handoffs (`next_developer: "bob"`)
- âœ… Team-ADRs (mit Discussion-Phase)
- âœ… Code Review fÃ¼r AI-Code (wie fÃ¼r menschlichen Code)
- âœ… Weekly Team-Sync (30 Min)

**Session-Naming-Convention:**

```
sessions/
â”œâ”€â”€ 2026-01-31_dev-alice_001.yml  # Alice's morning session
â”œâ”€â”€ 2026-01-31_dev-alice_002.yml  # Alice's afternoon session
â”œâ”€â”€ 2026-01-31_dev-bob_001.yml    # Bob's session
â””â”€â”€ 2026-01-31_dev-carol_001.yml  # Carol's session
```

**Handoff-Protocol (Explizit):**

```yaml
# sessions/2026-01-31_dev-alice_002.yml
session:
  operator:
    type: "human"
    identity: "alice@company.com"
  handoff:
    state: "in_progress"
    next_developer: "bob@company.com"
    context_for_next:
      - "Started auth-system refactor on branch feature/auth-v2"
      - "See ADR-008 for decision rationale (OAuth2 not SAML)"
      - "Tests failing: test_refresh_token() needs debugging"
      - "PR #42 ready for your review"
    blockers:
      - "Need Bob's review on PR #42 before I can merge"
      - "API credentials for testing (ask ops-team)"
```

**Team-ADR-Workflow (mit Discussion-Phase):**

```markdown
# ADR-009: Database Migration Strategy

Status: ğŸŸ  Under Discussion (Conflicting Proposals)

Proposed by: Alice
Date: 2026-01-31
Deciders: Alice, Bob, Carol

## Context
Current migration approach (simple SQL runner) doesn't scale to multi-environment (dev, staging, prod).
Need better migration management.

## Proposed Decision
Use Prisma Migrate

## Conflicting Proposal (Bob)
Use Flyway

## Discussion Thread
- Alice: "Prisma Migrate integrates with our ORM"
- Bob: "Flyway more mature, better rollback support"
- Carol: "Prisma simpler, less overhead"

## Team Vote (2026-02-01)
- Alice: Prisma âœ“
- Bob: Flyway
- Carol: Prisma âœ“

â†’ Majority: Prisma Migrate

Status: ğŸŸ¢ Accepted (2026-02-01)
```

**Code Review fÃ¼r AI-Code:**

Behandle AI-generierten Code GENAUSO wie menschlichen Code:

```markdown
# PR #42: Implement OAuth2 Flow (by Alice + Claude)

## Description
Implements OAuth2 authorization code flow with refresh tokens.
Generated with Claude Sonnet 4.5.

## Checklist (Reviewer: Bob)
- [x] Code functional (tested locally)
- [x] Tests comprehensive (92% coverage)
- [x] Security: No hardcoded secrets âœ“
- [x] Performance: <100ms response time âœ“
- [ ] LGTM pending: Minor refactor in auth_manager.py L45

## Review Comments
Bob: "Line 45: Extract magic number 3600 (token expiry) to constant"
Alice: "Fixed in commit a3f7d92"
Bob: "LGTM, approved âœ“"
```

**Weekly Team-Sync (Agenda):**

```markdown
# Weekly Team Sync - 2026-01-31

## Attendees
Alice, Bob, Carol

## Agenda (30 Min)

1. **Last Week Achievements** (5 Min)
   - Alice: OAuth2 flow complete
   - Bob: Database migration system
   - Carol: Frontend refactor (90% done)

2. **Current Week Goals** (5 Min)
   - Alice: Payment integration
   - Bob: API performance optimization
   - Carol: Finish frontend, start mobile

3. **Blockers & Help Needed** (10 Min)
   - Alice: Need API credentials (Carol to request from ops)
   - Bob: Performance bottleneck in query X (Alice to pair-program)
   - Carol: None

4. **ADRs & Decisions** (5 Min)
   - ADR-009 approved (Prisma Migrate)
   - ADR-010 proposed (Deployment strategy) â†’ discuss next week

5. **Process Improvements** (5 Min)
   - Bob: "Can we automate session YAML validation?"
   - â†’ Action: Bob creates validate-session.py script
```

---

#### Mittlere Teams (5-15 Personen)

**Squad-basierte Organisation:**

```
Team (15 Personen)
â”œâ”€â”€ Squad 1: Frontend (5 Entwickler)
â”‚   â”œâ”€â”€ Lead: Alice
â”‚   â””â”€â”€ Sessions: sessions/squad-frontend/
â”œâ”€â”€ Squad 2: Backend (5 Entwickler)
â”‚   â”œâ”€â”€ Lead: Bob
â”‚   â””â”€â”€ Sessions: sessions/squad-backend/
â””â”€â”€ Squad 3: Platform (5 Entwickler)
    â”œâ”€â”€ Lead: Carol
    â””â”€â”€ Sessions: sessions/squad-platform/
```

**Session-Organisation pro Squad:**

```
sessions/
â”œâ”€â”€ squad-frontend/
â”‚   â”œâ”€â”€ 2026-01-31_dev-alice_001.yml
â”‚   â”œâ”€â”€ 2026-01-31_dev-dave_001.yml
â”‚   â””â”€â”€ SQUAD_CONTEXT.md  # Shared context fÃ¼r Squad
â”œâ”€â”€ squad-backend/
â”‚   â”œâ”€â”€ 2026-01-31_dev-bob_001.yml
â”‚   â””â”€â”€ SQUAD_CONTEXT.md
â””â”€â”€ squad-platform/
    â”œâ”€â”€ 2026-01-31_dev-carol_001.yml
    â””â”€â”€ SQUAD_CONTEXT.md
```

**Cross-Squad ADRs (Architecture-Level):**

```markdown
# ADR-015: API Gateway Strategy

Status: ğŸ”µ Proposed
Scope: Cross-Squad (Frontend, Backend, Platform)
Proposed by: Platform Squad
Deciders: Alice (Frontend Lead), Bob (Backend Lead), Carol (Platform Lead)

## Context
Currently: Each service has direct external exposure
Problem: No centralized auth, rate-limiting, monitoring

## Proposed Decision
Introduce API Gateway (Kong) managed by Platform Squad

## Impact Analysis

### Frontend Squad (Alice):
- âœ… Simplified auth (gateway handles)
- âŒ Need to update API endpoints (1 day work)
- Vote: Approve âœ“

### Backend Squad (Bob):
- âœ… Centralized rate-limiting
- âŒ Additional network hop (latency concern)
- Vote: Approve with conditions (latency <10ms) âœ“

### Platform Squad (Carol):
- âœ… We manage gateway (our responsibility)
- âŒ More infrastructure to maintain
- Vote: Approve âœ“

## Decision
ğŸŸ¢ Accepted (2026-02-05) - All squads approved
Implementation: Platform Squad (Week 7-8)
```

**Onboarding neuer Entwickler:**

```markdown
# Onboarding Checklist - New Developer: Eve

## Day 1: Setup & Context (4h)
- [ ] Read PROJEKT_FOKUS.md (30 Min)
- [ ] Read last 5 ADRs (30 Min)
- [ ] Setup dev environment (scripts/setup-dev.sh) (1h)
- [ ] Run app locally (1h)
- [ ] Join team Slack channels
- [ ] Intro meeting with Squad Lead (Alice) (30 Min)

## Day 2: First Session (4h)
- [ ] Pair-program with Alice (2h)
  - Run session-start.sh together
  - Implement small bug fix
  - Run session-end.sh
- [ ] Solo: Fix another small bug (2h)
  - Create your first session YAML
  - Create PR

## Day 3-5: First Real Feature (3 days)
- [ ] Implement feature from backlog (with Alice's guidance)
- [ ] Write ADR if architectural decision needed
- [ ] Code review from 2 squad members
- [ ] Deploy to staging

## Week 2: Autonomous
- [ ] Eve works autonomously
- [ ] Weekly sync with squad
- [ ] Onboarding complete âœ“
```

---

#### GroÃŸe Teams (15+ Personen)

**Multi-Squad mit Governance:**

```
Organization (30 Personen)
â”œâ”€â”€ Squad 1-5: Product Squads (5 Personen je)
â”‚   â””â”€â”€ Focus: Features
â”œâ”€â”€ Platform Squad (5 Personen)
â”‚   â””â”€â”€ Focus: Infrastructure, DevOps
â””â”€â”€ Architecture Review Board (ARB)
    â”œâ”€â”€ 3 Senior Architects
    â””â”€â”€ Reviews: Critical ADRs, Tech-Stack-Entscheidungen
```

**Governance-Struktur:**

```markdown
# ADR Approval Process (Enterprise)

## Levels

### Level 1: Squad-Internal ADRs
- Scope: Only affects one squad
- Approval: Squad Lead
- Examples: Component design, local refactoring

### Level 2: Cross-Squad ADRs
- Scope: Affects 2+ squads
- Approval: Affected Squad Leads (Majority Vote)
- Examples: API contracts, shared libraries

### Level 3: Architecture ADRs
- Scope: Platform-wide impact
- Approval: Architecture Review Board (ARB)
- Examples: Database choice, deployment strategy, auth system

## ARB Meeting Schedule
- Bi-weekly (every 2 weeks)
- Duration: 2h
- Agenda: Review Level 3 ADRs

## ARB Composition
- Alice (Frontend Architect)
- Bob (Backend Architect)
- Carol (Platform Architect)
```

**Session-Koordination (Enterprise-Scale):**

```
sessions/
â”œâ”€â”€ squad-frontend-web/
â”‚   â””â”€â”€ [sessions]
â”œâ”€â”€ squad-frontend-mobile/
â”‚   â””â”€â”€ [sessions]
â”œâ”€â”€ squad-backend-api/
â”‚   â””â”€â”€ [sessions]
â”œâ”€â”€ squad-backend-data/
â”‚   â””â”€â”€ [sessions]
â”œâ”€â”€ squad-platform-infra/
â”‚   â””â”€â”€ [sessions]
â”œâ”€â”€ squad-platform-monitoring/
â”‚   â””â”€â”€ [sessions]
â””â”€â”€ TEAM_DASHBOARD.md  # Auto-generated: Squad Status Overview
```

**Team-Dashboard (Auto-Generated):**

```markdown
# Team Dashboard - Last Updated: 2026-01-31 18:00

## Squad Status

| Squad | Current Sprint | Active Sessions | Blockers | Health |
|-------|----------------|----------------|----------|--------|
| Frontend-Web | Sprint 12 | 3 | 0 | ğŸŸ¢ Green |
| Frontend-Mobile | Sprint 12 | 2 | 1 (API issue) | ğŸŸ¡ Yellow |
| Backend-API | Sprint 12 | 4 | 0 | ğŸŸ¢ Green |
| Backend-Data | Sprint 12 | 3 | 2 (performance) | ğŸ”´ Red |
| Platform-Infra | Sprint 12 | 2 | 0 | ğŸŸ¢ Green |
| Platform-Monitoring | Sprint 12 | 1 | 0 | ğŸŸ¢ Green |

## Recent ADRs (Last 7 Days)
- ADR-042: Migrate to gRPC (Backend-API) - ğŸŸ¢ Approved
- ADR-043: Multi-region deployment (Platform-Infra) - ğŸ”µ Under Review
- ADR-044: GraphQL federation (Backend-API, Frontend-Web) - ğŸŸ  Discussion

## Cross-Squad Dependencies
- Frontend-Mobile blocked by Backend-API (ADR-042 implementation)
  - Expected resolution: Week 8
- Backend-Data performance issue affecting all squads
  - Incident: INC-234
  - Owner: Bob (Backend-Data Lead)
  - ETA: 2026-02-03
```

---

### 3.3 Skalierung nach Projekt-Typ

#### Web-Applikationen

**Stack-Beispiele:**
- **Frontend:** React, Vue, Angular, Svelte, Next.js, Remix
- **Backend:** Node.js, Django, Spring Boot, Laravel, Ruby on Rails
- **Database:** PostgreSQL, MySQL, MongoDB

**Spezielle Ãœberlegungen:**

1. **Performance-Budgets:**
   ```markdown
   ## Quality Gates - Web-App-Spezifisch

   - [ ] Lighthouse Score >90
   - [ ] First Contentful Paint (FCP) <1.8s
   - [ ] Largest Contentful Paint (LCP) <2.5s
   - [ ] Time to Interactive (TTI) <3.8s
   - [ ] Cumulative Layout Shift (CLS) <0.1
   ```

2. **CI/CD Pipeline (Web-Specific):**
   ```yaml
   # .github/workflows/web-ci.yml
   jobs:
     lighthouse:
       runs-on: ubuntu-latest
       steps:
         - name: Run Lighthouse CI
           run: |
             npm install -g @lhci/cli
             lhci autorun --config=./lighthouserc.json
         - name: Check Performance Budget
           run: lhci assert --preset lighthouse:recommended
   ```

3. **Deployment-Strategien:**
   ```markdown
   # ADR-020: Deployment Strategy (Web-App)

   Decision: Vercel (Frontend) + Railway (Backend)

   Alternatives:
   - AWS (EC2 + RDS): âœ… Flexible, âŒ High complexity
   - Heroku: âœ… Simple, âŒ Expensive at scale
   - Netlify + Supabase: âœ… Good DX, âŒ Lock-in

   Chosen: Vercel + Railway
   - âœ… Excellent DX (git push = deploy)
   - âœ… Auto-scaling
   - âœ… Reasonable pricing
   - âŒ Vendor lock-in (mitigated: containerized backend)
   ```

---

#### Mobile-Applikationen

**Stack-Beispiele:**
- **Cross-Platform:** React Native, Flutter
- **Native:** Swift (iOS), Kotlin (Android)

**Spezielle Ãœberlegungen:**

1. **App-GrÃ¶ÃŸe Budgets:**
   ```markdown
   ## Quality Gates - Mobile-App-Spezifisch

   - [ ] APK/IPA Size <50 MB (without assets)
   - [ ] APK/IPA Size <100 MB (with assets)
   - [ ] Cold Start Time <2s
   - [ ] Warm Start Time <1s
   - [ ] Battery Usage <5% per hour (idle)
   - [ ] Memory Usage <100 MB (typical)
   ```

2. **Platform-Specific Testing:**
   ```bash
   # CI/CD for Mobile (Fastlane)

   # iOS
   fastlane ios test
   fastlane ios beta  # TestFlight

   # Android
   fastlane android test
   fastlane android beta  # Play Store Internal Testing
   ```

3. **Deployment-Pipeline:**
   ```markdown
   # ADR-025: Mobile CI/CD Strategy

   Decision: GitHub Actions + Fastlane + App Center

   Workflow:
   1. Push to main â†’ Run tests
   2. Tag release â†’ Build app
   3. Upload to App Center (beta)
   4. Manual approval â†’ Submit to stores
   ```

---

#### CLI-Tools

**Stack-Beispiele:**
- Go (Cobra), Rust (Clap), Python (Click), Node.js (Commander)

**Spezielle Ãœberlegungen:**

1. **Binary-GrÃ¶ÃŸe Budgets:**
   ```markdown
   ## Quality Gates - CLI-Tool-Spezifisch

   - [ ] Binary Size <10 MB (Go/Rust)
   - [ ] Binary Size <50 MB (Node.js with pkg)
   - [ ] Cold Start Time <100ms
   - [ ] Cross-Platform (Linux, Mac, Windows)
   - [ ] No Runtime Dependencies (static binary preferred)
   ```

2. **Distribution:**
   ```markdown
   # ADR-030: CLI Distribution Strategy

   Decision: Homebrew (Mac), Scoop (Windows), apt/yum (Linux)

   Installation:
   ```bash
   # Mac
   brew install my-cli-tool

   # Windows
   scoop install my-cli-tool

   # Linux
   sudo apt install my-cli-tool
   ```

   Alternatives:
   - npm install -g: âœ… Simple, âŒ Requires Node.js runtime
   - Manual binary download: âœ… No dependencies, âŒ Poor UX
   - Chosen: Package managers âœ“
   ```

3. **Testing:**
   ```bash
   # Integration tests for CLI

   # Test help command
   ./my-cli-tool --help | grep "Usage:"

   # Test actual functionality
   ./my-cli-tool scan ./test-repo | grep "10 TODOs found"

   # Test error handling
   ./my-cli-tool scan ./nonexistent && exit 1 || echo "Error handled"
   ```

---

#### Microservices

**Stack-Beispiele:**
- Go (gRPC), Node.js (REST), Java (Spring Cloud)

**Spezielle Ãœberlegungen:**

1. **Service-Level Quality Gates:**
   ```markdown
   ## Quality Gates - Microservice-Spezifisch

   Per Service:
   - [ ] Unit Tests >80% coverage
   - [ ] Integration Tests (with test containers)
   - [ ] Contract Tests (Pact)
   - [ ] Response Time P95 <200ms
   - [ ] Throughput >1000 req/s
   - [ ] Error Rate <0.1%
   ```

2. **Inter-Service Communication:**
   ```markdown
   # ADR-035: Service Communication Pattern

   Decision: gRPC for sync, RabbitMQ for async

   Sync (Request-Response):
   - Use gRPC (Protocol Buffers)
   - Timeout: 5s default
   - Retry: 3x with exponential backoff

   Async (Event-Driven):
   - Use RabbitMQ
   - Dead Letter Queue (DLQ) for failures
   - Idempotent consumers
   ```

3. **Deployment (Kubernetes):**
   ```yaml
   # k8s/deployment.yml
   apiVersion: apps/v1
   kind: Deployment
   metadata:
     name: my-service
   spec:
     replicas: 3
     selector:
       matchLabels:
         app: my-service
     template:
       spec:
         containers:
         - name: my-service
           image: my-service:v1.2.3
           resources:
             requests:
               memory: "128Mi"
               cpu: "250m"
             limits:
               memory: "512Mi"
               cpu: "1000m"
           livenessProbe:
             httpGet:
               path: /health
               port: 8080
             initialDelaySeconds: 10
             periodSeconds: 5
   ```

---

### 3.4 Entscheidungsmatrix: Was einbeziehen/weglassen?

**Quick Reference Tabelle:**

| Aspekt | Micro (1-2w) | Klein (2-6w) | Mittel (2-4m) | GroÃŸ (4-6m+) |
|--------|--------------|--------------|---------------|--------------|
| **Phase 0 Dauer** | 1 Tag | 3-5 Tage | 1-2 Wochen | 2-3 Wochen |
| **project-charter.md** | 1 Seite | 2 Seiten | 3-5 Seiten | 5-10 Seiten |
| **tech-stack.md** | Chosen only | + Rejected | + Detailed rationale | + ARB approval |
| **Test-Daten** | 3-5 Samples | 10-20 Samples | 20-50 Samples | 50-100 Samples |
| **ADRs Total** | 0-2 | 3-5 | 10-15 | 20-50+ |
| **Session YAML** | Vereinfacht (5 Felder) | VollstÃ¤ndig | + Team fields | + Squad context |
| **Backup Layers** | 2 (Git + Cloud) | 3 (+ Lokal) | 4 (+ DR drills) | 5 (+ Portable) |
| **CI/CD** | Optional | Basic (tests + lint) | Full (+ coverage) | Enterprise (+ multi-env) |
| **Quality Gates** | Manual | Automated basic | Automated full | + Platform-specific |
| **Team-Patterns** | Skip | Basic (2-5 dev) | Squad-based (5-15) | Multi-squad (15+) |
| **Retrospektiven** | Optional | Pro Session (5 Min) | Sprint Retros (2w) | + Monthly all-hands |
| **Compliance** | Skip | Optional | If needed | Mandatory (GDPR etc) |

**Entscheidungsbaum:**

```
Start Here: Was ist Ihr Projekt?
â”‚
â”œâ”€ Dauer?
â”‚  â”œâ”€ <2 Wochen â†’ MICRO
â”‚  â”œâ”€ 2-6 Wochen â†’ KLEIN
â”‚  â”œâ”€ 2-4 Monate â†’ MITTEL
â”‚  â””â”€ 4-6+ Monate â†’ GROSS
â”‚
â”œâ”€ Team-GrÃ¶ÃŸe?
â”‚  â”œâ”€ 1 Person â†’ Solo-Patterns
â”‚  â”œâ”€ 2-5 Personen â†’ Basic Team-Patterns
â”‚  â”œâ”€ 5-15 Personen â†’ Squad-basiert
â”‚  â””â”€ 15+ Personen â†’ Multi-Squad + ARB
â”‚
â”œâ”€ Projekt-Typ?
â”‚  â”œâ”€ Web â†’ Performance-Budgets (Lighthouse)
â”‚  â”œâ”€ Mobile â†’ App-GrÃ¶ÃŸe + Battery-Budgets
â”‚  â”œâ”€ CLI â†’ Binary-GrÃ¶ÃŸe + Cold-Start-Zeit
â”‚  â”œâ”€ Microservices â†’ Service-Level-Agreements
â”‚  â””â”€ Desktop â†’ Platform-Specific (macOS/Windows/Linux)
â”‚
â””â”€ Compliance-Anforderungen?
   â”œâ”€ Keine â†’ Standard-Prozess
   â”œâ”€ GDPR â†’ + Data Retention Policy
   â”œâ”€ HIPAA â†’ + Healthcare Compliance
   â””â”€ SOC2 â†’ + Security Audits
```

---

**Ende Teil I: Grundlagen**

Sie haben jetzt:
- âœ… Verstanden warum Vibe Coding ohne Struktur scheitert
- âœ… Die 6-Phasen-Methodik und 10 Kernprinzipien kennengelernt
- âœ… Gelernt wie Sie die Methodik an Ihre Projekt-GrÃ¶ÃŸe, Team-GrÃ¶ÃŸe, und Projekt-Typ anpassen

**NÃ¤chster Schritt:** [Teil II: Die 6-Phasen-Architektur](#teil-ii-die-6-phasen-architektur) (detaillierte Implementation jeder Phase)

**Oder:** [Quick Start Guide](QUICK_START_DE.md) fÃ¼r sofortigen Einstieg (5 Minuten)

---

# Teil II: Die 6-Phasen-Architektur

_[Wird fortgesetzt in nÃ¤chster Iteration...]_
